{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação Automática de Textos\n",
    "\n",
    "Até o momento, já conseguimos encontrar a probabilidade de, ao retirarmos um texto aleatório de uma coleção $c$, encontrarmos a palavra $w$, isto é:\n",
    "\n",
    "$P(w | c)$.\n",
    "\n",
    "Usando o Teorema de Bayes, podemos encontrar a probabilidade de um texto fazer parte de uma coleção $c$ sabendo que a palavra $w$ foi encontrada, isto é:\n",
    "\n",
    "$P(c | w) = \\frac{P(w | c)P(c)}{P(w)}$.\n",
    "\n",
    "Nesta aula, aprenderemos a usar essa ideia para classificar textos automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import urllib\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "frases_positivas = [\n",
    "    \"Que delícia esse sol quente!\",\n",
    "    \"Adoro sentir o calor do sol na pele!\",\n",
    "    \"Um dia quente é perfeito para curtir uma piscina!\",\n",
    "    \"O calor deixa tudo mais animado e colorido!\",\n",
    "    \"Nada melhor que um sorvete refrescante em um dia quente!\",\n",
    "    \"As roupas leves e soltinhas são a cara do verão!\",\n",
    "    \"Adoro o cheiro de protetor solar em um dia quente!\",\n",
    "    \"O calor deixa as pessoas mais alegres e descontraídas!\",\n",
    "    \"Um dia quente é a desculpa perfeita para tomar uma cerveja gelada!\",\n",
    "    \"A sensação de relaxamento que um dia quente traz é incomparável!\"\n",
    "]\n",
    "\n",
    "frases_negativas = [\n",
    "    \"Este calor está insuportável!\",\n",
    "    \"Eu não aguento mais suar o dia inteiro.\",\n",
    "    \"Não dá nem vontade de sair de casa com esse sol quente.\",\n",
    "    \"O ar-condicionado não dá conta de refrescar o ambiente.\",\n",
    "    \"Até o ventilador parece não estar funcionando direito hoje.\",\n",
    "    \"Eu odeio dias assim, prefiro o frio mil vezes!\",\n",
    "    \"Não tem um lugar com sombra nessa cidade?\",\n",
    "    \"Essa roupa colada no corpo me incomoda demais.\",\n",
    "    \"Quero chuva, quero frio, quero qualquer coisa, menos esse sol na minha cabeça!\",\n",
    "    \"Já acabou o verão? Porque eu não aguento mais esse calor infernal.\"\n",
    "]\n",
    "\n",
    "url = \"https://gist.githubusercontent.com/alopes/5358189/raw/2107d809cca6b83ce3d8e04dbd9463283025284f/stopwords.txt\"\n",
    "stopwords_list = urllib.request.urlopen(url).read().decode()\n",
    "stopwords_ptbr = set(stopwords_list.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "**Objetivo: entender como usar o `.fit` e o `.predict` em um classificador**\n",
    "\n",
    "Um classificador é um algoritmo que recebe como entrada um vetor de características de algum objeto e retorna a classe à qual esse objeto pertence. Uma das estratégias de classificação que existem é usar o Teorema de Bayes. Para isso, precisamos estimar as distribuições $P(w|c)$, $P(w)$ e $P(c)$.\n",
    "\n",
    "Quando estamos usando a presença ou não-presença de uma palavra como observação, podemos assumir que isso segue uma distribuição de Bernoulli, ou seja, existe uma probabilidade $p$ de que a palavra exista em um documento e uma probabilidade $1-p$ de que ela não exista, de uma forma semelhante a jogar uma moeda enviesada. O que precisamos, então, é descobrir os viéses dessa \"moeda\" no conjunto universo ($P(w)$) e dentro de cada uma das classes que nos interessam ($P(w|c_i)$ para toda classe $c_i$).\n",
    "\n",
    "O processo de descobrir esses viéses se chama *fit*. Para realizá-lo, precisamos fornecer ao classificador:\n",
    "\n",
    "1. Uma representação dos nossos documentos que indique a presença ou não de cada palavra no documento\n",
    "1. Uma anotação dizendo a qual classe cada documento pertence\n",
    "\n",
    "Depois que fazemos isso, podemos testar nosso classificador com um documento desconhecido, e ele retorna a classe mais provável à qual nosso sistema pertence. Esse processo de predição é chamado de *predict*.\n",
    "\n",
    "Então, teríamos um código como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['legal' 'legal' 'chato' 'chato']\n",
      "['legal']\n"
     ]
    }
   ],
   "source": [
    "X = np.array([ [1, 0, 0, 1], [1, 0, 1, 1], [0, 1, 1, 0], [0, 1, 0, 1]])\n",
    "y = np.array(['legal', 'legal', 'chato', 'chato'])\n",
    "\n",
    "classificador = BernoulliNB()\n",
    "classificador.fit(X, y)\n",
    "y_pred = classificador.predict(X)\n",
    "print(y_pred)\n",
    "\n",
    "y_pred_ = classificador.predict([[0,0,0,1]])\n",
    "print(y_pred_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar como usar essa ideia em nossos dados de frases sobre o calor. Gostaríamos de fazer um sistema que recebe como entrada uma frase e então informa se é uma frase dizendo que gosta ou se nào gosta do calor. Para isso:\n",
    "\n",
    "1. Una as listas de strings do dataset para encontrar um único dataset;\n",
    "1. Use o `CountVectorizer` para encontrar as representações vetoriais das frases que estão no nosso dataset; \n",
    "1. Crie um vetor `y` com classes correspondentes a gostar ou não gostar do calor;\n",
    "1. Treine (`.fit()`) um classificador do tipo `BernoulliNB()` para identificar frases positivas ou negativas;\n",
    "1. Teste o seu classificador com frases que você inventar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positiva' 'positiva' 'positiva' 'positiva' 'positiva' 'positiva'\n",
      " 'positiva' 'positiva' 'positiva' 'positiva' 'negativa' 'negativa'\n",
      " 'negativa' 'negativa' 'negativa' 'negativa' 'negativa' 'negativa'\n",
      " 'negativa' 'negativa']\n"
     ]
    }
   ],
   "source": [
    "# Resolva seu exercício aqui\n",
    "\n",
    "# 1. Una as listas de strings do dataset para encontrar um único dataset.\n",
    "dataset = frases_positivas + frases_negativas\n",
    "\n",
    "# 2. Use o CountVectorizer para encontrar as representações vetoriais das frases que estão no nosso dataset.\n",
    "vectorizer = CountVectorizer(binary=True, stop_words=stopwords_ptbr)\n",
    "X = vectorizer.fit_transform(dataset)\n",
    "\n",
    "# 3. Crie um vetor y com classes correspondentes a gostar ou não gostar do calor;\n",
    "y = ['positiva']*10 + ['negativa']*10\n",
    "\n",
    "# 4. Treine (.fit()) um classificador do tipo BernoulliNB() para identificar frases positivas ou negativas;\n",
    "classificador = BernoulliNB()\n",
    "classificador.fit(X, y)\n",
    "y_pred = classificador.predict(x)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negativa']\n"
     ]
    }
   ],
   "source": [
    "# 5.Teste o seu classificador com frases que você inventar.\n",
    "frase = [\"Não odeio calor\"]\n",
    "x_test = vectorizer.transform(frase)\n",
    "y_pred_ = classificador.predict(x_test)\n",
    "print(y_pred_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "**Objetivo: dividir um dataset em conjuntos de treino e teste**\n",
    "\n",
    "Até o momento, avaliamos nosso classificador de frases usando entradas manuais, e podemos ou não estar satisfeitos com ele. Porém, seria interessante termos um número que nos diz o quão efetiva foi nossa máquina no problema de classificação. É importante lembrarmos que fazer *fit* do classificador significa estimar as probabilidades relacionadas à estimação Bayesiana, e, portanto, *avaliar* o sistema significa avaliar até que ponto essas probabilidades (que foram estimadas num conjunto de dados restrito) podem extrapolar para dados nunca antes vistos pelo classificador.\n",
    "\n",
    "Isso significa que precisamos separar nossos dados entre aqueles que serão usados para treino e aqueles que serão usados para teste. Nunca use nenhum dado do conjunto de teste para nenhum outro fim que não seja somente avaliar o resultado final do classificador!\n",
    "\n",
    "A função `train_test_split` divide seu conjunto de dados em treinamento e teste. Uma chamada de exemplo é como abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X, y, train_size=0.6, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja a documentação da função `train_test_split` e responda:\n",
    "\n",
    "1. O que significa dizer `train_size=0.6`?\n",
    "- <font color=red>A particição de treino corresponde a 60% dos dados</font>\n",
    "\n",
    "2. O que significa dizer `stratify=y`?\n",
    "- <font color=red>Garante que a particição de treino tenha a mesma proporção de classes que o y</font>\n",
    "\n",
    "3. Quais são as dimensões de `X_train`, `y_train`, `X_test` e `y_test`, e porque temos essas dimensões?\n",
    "- <font color=red>12 elementos no treino e 8 elementos no teste</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3\n",
    "**Objetivo: entender como o `accuracy_score` funciona**\n",
    "\n",
    "Uma das possíveis métricas de avaliação de um classificador é o accuracy score, isto é, o número de elementos classificados corretamente dividido pelo total de elementos no conjunto de teste. A biblioteca sklearn tem uma função que calcula o accuracy score.\n",
    "\n",
    "Modifique o valor da variável `y_pred` abaixo para que o accuracy score seja igual a $0.25$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(['neg', 'neg', 'pos', 'pos']) # Dados corretos, retirados do conjunto de teste\n",
    "y_pred = np.array(['neg', 'pos', 'neg', 'neg']) # Predições (geradas pela máquina) realizadas sobre o conjunto de teste\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 4\n",
    "**Objetivo: treinar uma máquina de classificação e avaliá-la com accuracy score**\n",
    "\n",
    "Agora, vamos juntar o que vimos nos exercícios anteriores e aplicar para fazer uma máquina que classifica frases entre aquelas que são \"favoráveis\" ao calor e aquelas que são \"contrárias\" ao calor. Partindo do código abaixo, implemente esse classificador. Lembre-se que:\n",
    "\n",
    "1. Os métodos `fit` e `fit_transform` só devem ser chamados para os elementos do conjunto de treino,\n",
    "1. Os elementos do conjunto de teste só devem ser parâmetros dos métodos `predict` e `transform`.\n",
    "\n",
    "Qual foi o accuracy do seu classificador?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "# Dividindo dados entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y, train_size=0.6, stratify=y)\n",
    "\n",
    "# Treinamento da máquina\n",
    "vectorizer = CountVectorizer(binary=True, stop_words=stopwords_ptbr)\n",
    "X = vectorizer.fit_transform(X_train)\n",
    "\n",
    "classificador = BernoulliNB()\n",
    "classificador.fit(X, y_train)\n",
    "\n",
    "# Teste da máquina\n",
    "X_ = vectorizer.transform(X_test)\n",
    "y_pred = classificador.predict(X_)\n",
    "\n",
    "# Avaliação\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5\n",
    "**Objetivo: concentrar várias etapas do processo de classificação em uma pipeline**\n",
    "\n",
    "Você deve ter percebido que o treino e o teste do processo de classificação executam as mesmas etapas, na mesma ordem. A biblioteca `sklearn` permite que juntemos essas duas etapas em uma única máquina através de uma `pipeline`. A pipeline é declarada usando uma lista de tuplas. Cada elemento da tupla é uma das etapas do processo de classificação, e define um nome (que pode ser qualquer coisa) e um objeto do `sklearn`. Então, os métodos `fit` e `predict` são chamados diretamente na pipeline. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Classe 1']\n"
     ]
    }
   ],
   "source": [
    "minha_pipeline = Pipeline([\n",
    "                            ('meu_vetorizador', CountVectorizer()),\n",
    "                            ('meu_classificador', BernoulliNB())\n",
    "                            ])\n",
    "minha_pipeline.fit([\"olá\", \"mundo\"], ['Classe 1', 'Classe 2'])\n",
    "y_pred = minha_pipeline.predict([\"olá\"])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nesse código, altere seu classificador para que use uma pipeline para tornar o código do exercício 4 o mais compacto que conseguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_classifier = Pipeline([\n",
    "    ('meu_vetorizador', CountVectorizer(binary=True, stop_words=stopwords_ptbr)),\n",
    "    ('meu_classificador', BernoulliNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y, train_size=0.6, stratify=y)\n",
    "pipe_classifier.fit(X_train, y_train)\n",
    "y_pred = pipe_classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6\n",
    "**Objetivo: salvar um modelo do sklearn**\n",
    "\n",
    "Depois de treinar e avaliar nosso modelo, se gostamos dele, provavelmente vamos querer incorporá-lo em algum outro lugar. Para isso, precisaremos salvar o modelo em algum arquivo e então carregar esse arquivo no local em que vamos usar (ou: *fazer o deploy para produção*). A biblioteca para isso é a `joblib`. Joblib funciona parecido com o pickle, mas é mais eficaz para tipos numéricos. Um exemplo de uso é o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Classe 1']\n"
     ]
    }
   ],
   "source": [
    "minha_pipeline = Pipeline([\n",
    "                            ('meu_vetorizador', CountVectorizer()),\n",
    "                            ('meu_classificador', BernoulliNB())\n",
    "                            ])\n",
    "minha_pipeline.fit([\"olá\", \"mundo\"], ['Classe 1', 'Classe 2'])\n",
    "joblib.dump(minha_pipeline, 'meu_modelo.joblib')\n",
    "outra_pipeline = joblib.load('meu_modelo.joblib')\n",
    "y_pred = outra_pipeline.predict([\"olá\"])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Experimente salvar seu modelo de classificação e carregá-lo em uma outra variável.\n",
    "1. Qual é o tamanho do arquivo que contém o seu modelo?\n",
    "1. Envie seu modelo para um colega tentar carregá-lo, e tente carregar e usar o modelo de um colega. Para isso, use o canal do Discord."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7\n",
    "**Objetivo: corrigir um procedimento de treinamento e teste de um modelo**\n",
    "\n",
    "Muitas vezes, encontrar um *accuracy score* elevado é entendido como o \"sucesso\" de um modelo. Porém, é comum termos erros nos procedimentos de treino, teste e avaliação que prejudicam o processo e podem levar a falsos resultados positivos. No código abaixo, isso acontece pelo menos uma vez. Nele, um aluno gerou um classificador de reviews de filmes e está muito contente porque o resultado foi de 100% de acerto. Corrija todos os erros do código, e explique por que esses erros atrapalham o processo de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('datasets/IMDB Dataset.csv')\n",
    "X = df['sentiment'].to_numpy()\n",
    "y = df['review'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.5 GiB for an array with shape (50000, 49582) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17880\\2431012265.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         \u001b[1;33m(\u001b[0m\u001b[1;34m'meu_classificador'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         ])\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclassificador\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassificador\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[0mlabelbin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mCSR\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The object was not fitted with multilabel input.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         return label_binarize(\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mlabel_binarize\u001b[1;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msparse_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 18.5 GiB for an array with shape (50000, 49582) and data type int64"
     ]
    }
   ],
   "source": [
    "classificador = Pipeline([\n",
    "                        ('meu_vetorizador', CountVectorizer()),\n",
    "                        ('meu_classificador', BernoulliNB())\n",
    "                        ])\n",
    "classificador.fit(X,y)\n",
    "y = classificador.predict(X)\n",
    "acc = accuracy_score(y,y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <font color=red>O código não faz partição de treino e teste.</font>\n",
    "2. <font color=red>O classificador é treinado com X e y e depois usado para prever o mesmo X, obviamente retornará o mesmo y.</font>\n",
    "3. <font color=red>A acurácia é feita comparando a mesma variável, sempre daria 100%</font>\n",
    "4. <font color=red>X e y está trocado</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85325\n"
     ]
    }
   ],
   "source": [
    "#Correção\n",
    "df = pd.read_csv('datasets/IMDB Dataset.csv')\n",
    "X = df['review'].to_numpy()\n",
    "y = df['sentiment'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, stratify=y)\n",
    "\n",
    "classificador = Pipeline([\n",
    "    ('meu_vetorizador', CountVectorizer(binary=True, stop_words='english')),\n",
    "    ('meu_classificador', BernoulliNB())\n",
    "])\n",
    "\n",
    "classificador.fit(X_train, y_train)\n",
    "y_pred = classificador.predict(X_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 8\n",
    "**Objetivo: fazer e avaliar um classificador de textos**\n",
    "\n",
    "O spam-ham dataset tem vários e-mails que são classificados como spam (mensagem não-requisitada) ou ham (mensagem normal). A ideia dessa classificação é que e-mail do tipo spam devem ser movidos para uma pasta específica.\n",
    "\n",
    "1. Faça um sistema que recebe como entrada o texto de um e-mail e identifica se ele é spam ou ham.\n",
    "1. Avalie seu sistema em relação ao accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/spam_ham_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8380860318994683\n"
     ]
    }
   ],
   "source": [
    "X = df['text'].to_numpy()\n",
    "y = df['label'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, stratify=y)\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(binary=True, stop_words='english')),\n",
    "    ('classifier', BernoulliNB())\n",
    "])\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "42e34ec1a81382d7a35a13fd98192c35dabe0890684b7b0a474deec672e3df02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
