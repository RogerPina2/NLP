{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging (análise morfológica)\n",
    "\n",
    "Part-of-speech tagging é a tarefa de identificar as classes morfológicas das palavras de uma frase. Nesta aula, usaremos o conceito de n-gramas para nos ajudar a identificar classes morfológicas automaticamente.\n",
    "\n",
    "## Exercício 1\n",
    "**Objetivo: lembrar-se do que é uma classe morfológica**\n",
    "\n",
    "Nas frases abaixo, identifique os *substantivos*, os *verbos*, os *adjetivos* e os *advérbios*:\n",
    "\n",
    "1. Hoje eu acordei serenamente e vi que era um dia lindo e calmo.\n",
    "1. A mutação dos fungos é capaz de controlar a mente das pessoas!\n",
    "1. Todo dia, o Sol da manhã vem e nos desafia!\n",
    "1. Não adianta tentar fazer um sistema automático que faz alguma coisa que não entendemos o resultado!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "**Objetivo: representar classes morfológicas no computador**\n",
    "\n",
    "Quando falamos de *part-of-speech tagging*, queremos associar cada token de um texto a uma etiqueta que representa sua classe morfológica. A tarefa de rotular tokens pode ser realizada por pacotes prontos, por exemplo pelo `DefaultTagger` do `nltk`, que atribui o mesmo rótulo a qualquer token que seja recebido.\n",
    "\n",
    "No exemplo abaixo, usamos o rótulo `N` (*noun*, ou \"substantivo\").\n",
    "\n",
    "1. Como um par token+rótulo é representado?]\n",
    "    - <font color=red> Uma tupla (token, rótulo) </font>\n",
    "\n",
    "\n",
    "2. Na frase usada como exemplo, qual é a acurácia do rotulador?\n",
    "    - <font color=red> Número de substantivos / quantidade de tokens = 2/9 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uma', 'N'),\n",
       " ('frase', 'N'),\n",
       " ('qualquer', 'N'),\n",
       " (':', 'N'),\n",
       " ('ótimo', 'N'),\n",
       " ('para', 'N'),\n",
       " ('dar', 'N'),\n",
       " ('aula', 'N'),\n",
       " ('!', 'N')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "default_tagger = DefaultTagger('N')\n",
    "tokens = re.findall(r'\\w+|[.,!?:]+', \"uma frase qualquer: ótimo para dar aula!\")\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3\n",
    "**Objetivo: entender como funciona um banco de dados de tags**\n",
    "\n",
    "Uma estratégia menos \"inocente\" que atribuir a mesma tag a todos os tokens é criar um grande banco de dados nos quais relacionamos palavras a tags. Por exemplo, a palavra \"Brasil\" é um substantivo, a palavra \"andar\" é um verbo, e assim por diante. Para construir esse dicionário, podemos usar um grande conjunto de frases rotuladas.\n",
    "\n",
    "O corpus [macmorpho](http://www.nilc.icmc.usp.br/macmorpho/) tem uma série de anotações de *part-of-speech* na língua portuguesa.\n",
    "\n",
    "1. Nos códigos abaixo, verifique como as tags são associadas a palavras no corpus macmorpho.\n",
    "    - <font color=red> As tags são associadas as palavras por um \"_\" ao final da palavra seguido pelo símbolo do rótulo </font>\n",
    "\n",
    "\n",
    "2. Como a instrução `re.findall` foi usada para extrair as tuplas de tokens/tags nesse corpus? A expressão regular usada poderia ser melhorada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jersei_N atinge_V média_N de_PREP Cr$_CUR 1,4_NUM milhão_N na_PREP+ART venda_N da_PREP+ART Pinhal_NPROP em_PREP São_NPROP Paulo_NPROP ._PU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./datasets/macmorpho-train.txt', 'r', encoding='utf-8') as f:\n",
    "    print(f.readline())\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jersei', 'N'), ('atinge', 'V'), ('média', 'N'), ('de', 'PREP'), ('Cr$', 'CUR'), ('1,4', 'NUM'), ('milhão', 'N'), ('na', 'PREP+ART'), ('venda', 'N'), ('da', 'PREP+ART'), ('Pinhal', 'NPROP'), ('em', 'PREP'), ('São', 'NPROP'), ('Paulo', 'NPROP'), (' .', 'PU')]\n"
     ]
    }
   ],
   "source": [
    "with open('./datasets/macmorpho-train.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens = [re.findall(r'([0-9,]+|\\w+|[\\W]+|\\w+\\$)\\_([\\w\\+]+)', line) for line in f.readlines()]\n",
    "print(tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 4\n",
    "**Objetivo: avaliar um pos-tagger**\n",
    "\n",
    "O método `accuracy` permite avaliar um tagger com base em um gabarito. Por exemplo, podemos usar a base de teste do *macmorpho* para fazer essa avaliação.\n",
    "\n",
    "1. Com base no código abaixo, qual é a acurácia do tagger se simplesmente assumirmos que todas as palavras são substantivos?\n",
    "    - <font color=red> 0.2048628435917992 </font>\n",
    "\n",
    "\n",
    "2. E se a tag padrão for `V` (verbo), qual seria a acurácia?\n",
    "    - <font color=red> 0.1105043924809248 </font>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tagger = DefaultTagger('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2048628435917992"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./datasets/macmorpho-test.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens_test = [re.findall(r'([0-9,]+|\\w+|[\\W]+|\\w+\\$)\\_([\\w\\+]+)', line) for line in f.readlines()]\n",
    "default_tagger.accuracy(tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5\n",
    "**Objetivo: treinar e avaliar um pos-tagger**\n",
    "\n",
    "Uma maneira de encontrar quais palavras devem receber determinadas tags é treinar um dicionário em um grande banco de dados e simplesmente atribuir a cada palavra o rótulo que é mais comum a essa palavra, ou seja, usar a probabilidade da tag $t$ dado que sabemos a palavra $w$:\n",
    "\n",
    "$$\n",
    "P(t | w)\n",
    "$$\n",
    "\n",
    "Isso pode ser implementado no nltk usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8922594787327679"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "unigram_tagger = UnigramTagger(tokens, backoff=default_tagger)\n",
    "unigram_tagger.accuracy(tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Diferente do `sklearn`, fazemos o treinamento do `UnigramTagger` já quando ele é instanciado. Qual é o parâmetro que indica o banco de dados de treinamento?\n",
    "    - <font color=red> primeiro parâmetro (train: tokens, test: tokens_test) </font>\n",
    "\n",
    "\n",
    "2. O que significa `backoff`, e por que ele é importante?\n",
    "    - <font color=red> para classificar uma palavra que não exista no vocabulário </font>\n",
    "    \n",
    "    \n",
    "3. Qual é a acurácia do `UnigramTagger` com backoff no `macmorpho-test`?\n",
    "    - <font color=red> 0.8922594787327679 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6\n",
    "**Objetivo: treinar e avaliar um pos-tagger baseado em bigramas**\n",
    "\n",
    "Algumas palavras, como \"Brasil\", claramente pertencem a uma classe morfológica única. Outras, como \"andar\", podem assumir classes gramaticais diferentes dependendo do contexto (\"eu moro no terceiro andar\" / \"vou andar até ali\"). Para resolver essa questão, podemos usar *n-gramas* ao invés de palavras para encontrar a tag, isto é:\n",
    "\n",
    "$$\n",
    "P(t_n | w_n, w_{n-1}, ..., w_{n-N-1})\n",
    "$$\n",
    "\n",
    "Podemos implementar um tagger baseado em bi-gramas usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9103059319515846"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import NgramTagger\n",
    "bigram_tagger = NgramTagger(n=2, train=tokens, backoff=unigram_tagger)\n",
    "bigram_tagger.accuracy(tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste código:\n",
    "\n",
    "1. Onde especificamos que o tagger deve conter bigramas?\n",
    "    - <font color=red>No primeiro parâmetro da função NgramTagger (n=2)</font>\n",
    "\n",
    "\n",
    "2. Qual é a importância do backoff nesse caso?\n",
    "    - <font color=red>Caso apareça uma dupla de palavras inexistentes no vocabulário.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7\n",
    "**Objetivo: implementar e testar taggers com n-gramas**\n",
    "\n",
    "Tomando por base os códigos anteriores, implemente e avalie um pos-tagger com trigramas e depois com tetragramas.\n",
    "\n",
    "1. A acurácia aumenta significativamente quando aumentamos o contexto?\n",
    "    - <font color=red>Não. A acurácia não aumenta significativamente.</font>\n",
    "\n",
    "\n",
    "2. O que acontece com a acurácia se removermos o backoff?\n",
    "    - <font color=red>O valor de acurácia cai drásticamente, ou seja, não há tantas repetições de 3 e 4 palavras.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementação de um pos-tagger com trigramas\n",
    "trigram_tagger = NgramTagger(n=3, train=tokens, backoff=bigram_tagger)\n",
    "trigram_tagger_ = NgramTagger(n=3, train=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementação de um pos-tagger com tetragramas\n",
    "tetragram_tagger = NgramTagger(n=4, train=tokens, backoff=trigram_tagger)\n",
    "tetragram_tagger_ = NgramTagger(n=4, train=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8922594787327679\n",
      "0.9103059319515846\n",
      "0.9106703368783392\n",
      "0.909734096528062\n"
     ]
    }
   ],
   "source": [
    "print(unigram_tagger.accuracy(tokens_test))\n",
    "print(bigram_tagger.accuracy(tokens_test))\n",
    "print(trigram_tagger.accuracy(tokens_test))\n",
    "print(tetragram_tagger.accuracy(tokens_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17991512168321439\n",
      "0.13031120180744843\n"
     ]
    }
   ],
   "source": [
    "print(trigram_tagger_.accuracy(tokens_test))\n",
    "print(tetragram_tagger_.accuracy(tokens_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 8\n",
    "**Objetivo: testar o tagger em situações reais**\n",
    "\n",
    "Verifique como seu tagger se comporta quando tenta rotular:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Uma frase que poderia ser usada normalmente na língua escrita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ola', 'N'), ('mundo', 'N'), ('cruel!', 'N')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger.tag(\"ola mundo cruel!\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Uma frase com neologismos usados na Internet como \"vc\", \"rsrsrs\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ow,', 'N'),\n",
       " ('vc', 'N'),\n",
       " ('vai', 'V'),\n",
       " ('colar', 'V'),\n",
       " ('aqui', 'ADV'),\n",
       " ('em', 'PREP'),\n",
       " ('casa?', 'N'),\n",
       " ('Se', 'KS'),\n",
       " ('tu', 'PROPESS'),\n",
       " ('for', 'V'),\n",
       " ('me', 'PROPESS'),\n",
       " ('avisa', 'V'),\n",
       " ('q', 'N'),\n",
       " ('horas', 'N'),\n",
       " ('vc', 'N'),\n",
       " ('chega', 'V'),\n",
       " ('pra', 'PREP'),\n",
       " ('eu', 'PROPESS'),\n",
       " ('abrir', 'V'),\n",
       " ('o', 'ART'),\n",
       " ('portão', 'N'),\n",
       " ('pra', 'PREP'),\n",
       " ('vc.', 'N')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger.tag(\"Ow, vc vai colar aqui em casa? Se tu for me avisa q horas vc chega pra eu abrir o portão pra vc.\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Emoticons como \":)\" ou \":-)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Parsa,', 'N'),\n",
       " ('acordei', 'N'),\n",
       " ('bem', 'ADV'),\n",
       " ('hoje', 'ADV'),\n",
       " ('e', 'KC'),\n",
       " ('fui', 'V'),\n",
       " ('pra', 'PREP'),\n",
       " ('academia', 'N'),\n",
       " ('cedo.', 'N'),\n",
       " ('Mó', 'N'),\n",
       " ('feliz', 'ADJ'),\n",
       " (':)', 'N')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger.tag(\"Parsa, acordei bem hoje e fui pra academia cedo. Mó feliz :)\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 9\n",
    "**Objetivo: salvar o tagger e carregar em outro contexto**\n",
    "\n",
    "Usando `joblib`, podemos salvar nosso tagger para evitar ter que carregar toda a base de dados em outro contexto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('esta', 'PROADJ'),\n",
       " ('alsdkfjasdljf', 'N'),\n",
       " ('uma', 'ART'),\n",
       " ('frase,', 'N'),\n",
       " (':-)', 'N'),\n",
       " ('cheia', 'ADJ'),\n",
       " ('de', 'PREP'),\n",
       " ('coisas', 'N'),\n",
       " ('novas', 'ADJ')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(trigram_tagger, 'tagger.joblib')\n",
    "tagger = joblib.load('tagger.joblib')\n",
    "tagger.tag(\"esta alsdkfjasdljf uma frase, :-) cheia de coisas novas\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o `joblib`, salve o melhor tagger que você encontrou nesta aula. Envie o arquivo `.joblib` para um colega e, ao receber um tagger de volta, teste-o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111468663979414\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk import NgramTagger\n",
    "import joblib\n",
    "\n",
    "with open('./datasets/macmorpho-train.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens = [re.findall(r'(\\w+|[\\W]+)\\_([\\w\\+]+)', line) for line in f.readlines()]\n",
    "\n",
    "default_tagger = DefaultTagger('N')\n",
    "unigram_tagger = UnigramTagger(tokens, backoff=default_tagger)\n",
    "bigram_tagger = NgramTagger(n=2, train=tokens, backoff=unigram_tagger)\n",
    "trigram_tagger = NgramTagger(n=3, train=tokens, backoff=bigram_tagger)\n",
    "\n",
    "with open('./datasets/macmorpho-test.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens_test = [re.findall(r'(\\w+|[\\W]+)\\_([\\w\\+]+)', line) for line in f.readlines()]\n",
    "    \n",
    "print(trigram_tagger.accuracy(tokens_test))\n",
    "\n",
    "joblib.dump(trigram_tagger, 'tagger.joblib')\n",
    "tagger = joblib.load('tagger.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "28a48ae6583e1b94abe98b0fc0a2fe606019d17909ce475d8d225fed8710924f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
