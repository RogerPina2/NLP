{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos linguísticos com n-gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até o momento, usamos modelos probabilísticos para a probabilidade de encontrar uma palavra $w$ em algum documento dentro da coleção $c$, isto é: $P(w | c)$. Implicitamente, isso quer dizer que a *ordem* das palavras dentro de um documento não tem impacto em seu significado. Metaforicamente, é como se colocássemos todas as palavras em uma grande sacola, e por isso esse tipo de representação baseado na presença ou não de palavras é chamado de *bag-of-words*.\n",
    "\n",
    "O modelo bag-of-words é eficaz para muitas aplicações, mas pode perder características importantes de uma palavra: por um lado, é pouco provável que um texto que mencione \"ornitorrincos\" e \"cangurus\" não se refira a ornitorrincos e cangurus; por outro lado, o texto: \"ornitorrincos são mais perigosos que cangurus\" é muito diferente de \"cangurus são mais perigosos que ornitorrincos\".\n",
    "\n",
    "Uma maneira de criar modelos para a *ordem* em que as palavras aparecem em um texto é chamado de modelo linguístico gerador (ou generativo ou gerativo, dependendo da tradução que você adotar) (*generative linguistic model*). Nesse tipo de modelo, estimamos a probabilidade de encontrar a $n$-ésima palavra de uma sequência com base na palavra anterior, isto é:\n",
    "\n",
    "$$\n",
    "P(w_n | w_{n-1})\n",
    "$$\n",
    "\n",
    "Podemos fazer um pequeno modelo para a passagem:\n",
    "\n",
    "    Passa um, passa dois, passa três\n",
    "\n",
    "Nesse caso, nosso modelo nos dá probabilidades como:\n",
    "\n",
    "* $P(\\text{passa} | \\text{um}) = 1$\n",
    "* $P(\\text{passa} | \\text{dois}) = 1$\n",
    "* $P(\\text{dois} | \\text{passa}) = 1/3$\n",
    "\n",
    "Veja que essas probabilidades são estimadas por contagem em um conjunto de dados de treino!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "**Objetivo: calcular probabilidades de um modelo linguístico baseado em uma frase**\n",
    "\n",
    "Na passagem:\n",
    "\n",
    "    Joana foi passear com alguns de seus sete cachorros durante uma tarde ensolarada, e se encontrou com uma amiga. Uma pessoa ali presente também parou para conversar com elas, e também pararam alguns outros cachorros para brincar com os de Joana.\n",
    "\n",
    "Calcule:\n",
    "\n",
    "* $P(\\text{tarde} | \\text{uma})$\n",
    "    - <font color=red>1/3</font>\n",
    "\n",
    "\n",
    "* $P(\\text{alguns} | \\text{com})$\n",
    "    - <font color=red>1/4</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "1 3\n",
      "2 4\n"
     ]
    }
   ],
   "source": [
    "texto = 'Joana foi passear com alguns de seus sete cachorros durante uma tarde ensolarada, e se encontrou com uma amiga. Uma pessoa ali presente também parou para conversar com elas, e também pararam alguns outros cachorros para brincar com os de Joana.'\n",
    "palavras = texto.upper().split()\n",
    "print(len(palavras))\n",
    "print(palavras.count('TARDE'), palavras.count('UMA'))\n",
    "print(palavras.count('ALGUNS'), palavras.count('COM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "**Objetivo: estimar um vocabulário à partir de dados**\n",
    "\n",
    "Usando reviews do `IMDB`, monte um vocabulário de todas as palavras que podem ser usadas para gerar reviews de filmes. Use tokens também para representar os sinais de pontuação, isto é, ` \"aqui, agora\"` deve ser tokenizado como `['aqui', ',', 'agora']`. Para isso, complete o código abaixo trocando a expressão regular que aparece no `re.findall`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_csv('datasets/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17995\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "#REGEX = r'[a-z]+'\n",
    "REGEX = r'[A-Za-z0-9]\\w*|[^\\w\\s]'\n",
    "#REGEX = r'\\b\\w+\\b|[,.!]'\n",
    "for text in df['review'][0:1000]:\n",
    "    tokens = re.findall(REGEX, text.lower())\n",
    "    vocab = vocab.union(set(tokens))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3\n",
    "**Objetivo: estimar um modelo linguístico à partir de dados**\n",
    "\n",
    "O código abaixo realiza a contagem de tokens que seguem outros tokens usando a base de dados IMDB, bem como a quantidade total de aparições de cada token. Interprete o código e, depois, execute. Com base no resultado dele, estime:\n",
    "\n",
    "* A probabilidade de a palavra `under` ser seguida pela palavra `her`.\n",
    "* A probabilidade da palavra `violence` aparecer no fim de uma frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {key: {'[TOTAL]':0} for key in vocab}\n",
    "\n",
    "for text in df['review'][0:1000]:\n",
    "    tokens = re.findall(REGEX, text.lower())\n",
    "    for i in range(len(tokens)-1):\n",
    "        wn = tokens[i+1]\n",
    "        wn1 = tokens[i]\n",
    "        if wn in model[wn1].keys():\n",
    "            model[wn1][wn] += 1\n",
    "        else:\n",
    "            model[wn1][wn] = 1\n",
    "            \n",
    "        model[wn1]['[TOTAL]'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03571428571428571\n",
      "0.19642857142857142\n"
     ]
    }
   ],
   "source": [
    "#A probabilidade de a palavra under ser seguida pela palavra her -> P(her|under)\n",
    "print(model['under']['her']/model['under']['[TOTAL]'])\n",
    "\n",
    "#A probabilidade da palavra violence aparecer no fim de uma frase. -> P(.|violence)\n",
    "print(model['violence']['.']/model['violence']['[TOTAL]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 4\n",
    "**Objetivo: programar um sistema de sugestão de palavras**\n",
    "\n",
    "Com base no modelo que foi estimado no exercício anterior, programe uma função que recebe uma palavra e retorna uma possível palavra seguinte. Caso a palavra usada como base não faça parte do vocabulário do modelo, ele deve retornar uma palavra aleatória de seu vocabulário. Use a funcionalidade de `np.random.choice` para fazer escolhas com probabilidades pré-definidas, como abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "um\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.random.choice(['um', 'dois', 'tres'], p=[0.5, 0.2, 0.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sugestao_de_palavras(token):\n",
    "    if token in model:\n",
    "        choices = [word for word in model[token] if word != '[TOTAL]']\n",
    "        probs = [model[token][word]/model[token]['[TOTAL]'] for word in choices]\n",
    "        return np.random.choice(choices, p=probs)\n",
    "\n",
    "    else: \n",
    "        return np.random.choice(list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'film'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sugestao_de_palavras('superior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5\n",
    "**Objetivo: fazer um gerador de textos**\n",
    "\n",
    "Agora, podemos fazer um gerador de textos. Para isso, vamos gerar uma palavra, e então incorporá-la ao texto que temos, gerando palavras sucessivamente.\n",
    "\n",
    "Complete a função `gerar` abaixo para que ela retorne uma string com `n_tokens` novas palavras geradas à partir da string de entrada `s`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar(s, n_tokens=10):\n",
    "    REGEX = r'[A-Za-z0-9]\\w*|[^\\w\\s]'\n",
    "    tokens = re.findall(REGEX, s.lower())\n",
    "    size = len(tokens)\n",
    "    \n",
    "    for n in range(n_tokens):\n",
    "        tokens.append(sugestao_de_palavras(tokens[-1]))\n",
    "    \n",
    "    return ' '.join(tokens[size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have bought this film out what kept that day australia'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'After watching the movie, I'\n",
    "gerar(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6\n",
    "**Objetivo: refletir sobre a aplicação de n-gramas em modelos linguísticos**\n",
    "\n",
    "Até o momento, usamos apenas uma palavra do passado para determinar o contexto que gera uma nova palavra. Poderíamos, porém, usar um número arbitrário $N$ de palavras anteriores, isto é:\n",
    "\n",
    "$$\n",
    "P(w_n | w_{n-1}, w_{n-2}, ... , w_{n-N})\n",
    "$$\n",
    "\n",
    "Podemos fazer um pequeno modelo para a passagem:\n",
    "\n",
    "    Passa um, passa dois, passa três\n",
    "\n",
    "Nesse caso, um modelo como o que temos feito até o momento nos daria probabilidades como:\n",
    "\n",
    "* $P(\\text{passa} | \\text{um}) = 1$\n",
    "* $P(\\text{passa} | \\text{dois}) = 1$\n",
    "* $P(\\text{dois} | \\text{passa}) = 1/3$\n",
    "\n",
    "Um modelo com $N=2$, por sua vez, teria:\n",
    "\n",
    "* $P(\\text{passa} | \\text{um, passa}) = 1$\n",
    "* $P(\\text{passa} | \\text{dois, passa}) = 1$\n",
    "* $P(\\text{dois} | \\text{passa, um}) = 1$\n",
    "\n",
    "Neste momento, aparece um novo elemento importante para nós. Nossa coleção não está mais sendo descrita por palavras, e sim por conjuntos de palavras ordenadas! Esses conjuntos são chamados de n-gramas.\n",
    "\n",
    "A função abaixo permite extrair n-gramas de uma lista de tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('isto', 'é', 'um'), ('é', 'um', 'teste'), ('um', 'teste', 'e'), ('teste', 'e', 'n-gramas'), ('e', 'n-gramas', 'podem'), ('n-gramas', 'podem', 'ser'), ('podem', 'ser', 'legais')]\n"
     ]
    }
   ],
   "source": [
    "def get_ngrams(tokens, N):\n",
    "    ngrams = [tuple(tokens[i:i+N]) for i in range(len(tokens)-N+1)]\n",
    "    return ngrams\n",
    "\n",
    "print(get_ngrams(\"isto é um teste e n-gramas podem ser legais\".split(), N=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Qual é a vantagem em usar n-gramas com valores de $N$ maiores?\n",
    "    - <font color=red>Compreender o contexto da frase.</font>\n",
    "\n",
    "2. Quando $N$ aumenta, qual é a probabilidade de encontrarmos ocorrências de n-gramas em mais de um documento?\n",
    "    - <font color=red>Com N muito algo os n-gramas ficam cada vez mais específicos, diminuindo a chance de encontrar a ocorrência de n-gramas iguais.</font>\n",
    "\n",
    "3. Como essa propriedade poderia ser utilizada para detectar cópias em trabalhos escritos? \n",
    "    - <font color=red>Sim!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7\n",
    "**Objetivo: usar n-gramas para melhorar nosso modelo linguístico**\n",
    "\n",
    "O código abaixo mostra um modelo linguístico para fazer predições de palavras com base nas $N$ palavras anteriores. O código, inicialmente, usa $N=2$.\n",
    "\n",
    "Implemente um gerador de textos baseado neste novo modelo linguístico.\n",
    "\n",
    "Caso as duas palavras que estejam no fim do texto recebido como entrada não estejam no banco de dados deste modelo, o sistema deve \"chamar\" o modelo anterior (baseado em somente uma palavra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams_and_res(tokens, N):\n",
    "    ngrams = [tuple(tokens[i:i+N]) for i in range(len(tokens)-N)]\n",
    "    res = [tokens[i+N] for i in range(len(tokens)-N)]\n",
    "    return ngrams, res\n",
    "\n",
    "# Criar vocabulário\n",
    "vocab = set()\n",
    "all_ngrams = []\n",
    "all_res = []\n",
    "for text in df['review'][0:5000]:\n",
    "    tokens = re.findall(REGEX, text.lower())\n",
    "    n_grams,res = get_ngrams_and_res(tokens, 2)\n",
    "    all_ngrams += n_grams\n",
    "    all_res += res\n",
    "    vocab = vocab.union(set(n_grams))\n",
    "\n",
    "# Criar modelo\n",
    "model_n2 = {key: {'[TOTAL]':0} for key in vocab}\n",
    "\n",
    "for i in range(len(all_ngrams)):\n",
    "    wn = all_res[i]\n",
    "    wn1 = all_ngrams[i]\n",
    "    if wn in model_n2[wn1].keys():\n",
    "        model_n2[wn1][wn] += 1\n",
    "    else:\n",
    "        model_n2[wn1][wn] = 1\n",
    "        \n",
    "    model_n2[wn1]['[TOTAL]'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sugestao_de_palavras_n2(token):\n",
    "    if token in model_n2:\n",
    "        choices = [word for word in model_n2[token] if word != '[TOTAL]']\n",
    "        probs = [model_n2[token][word]/model_n2[token]['[TOTAL]'] for word in choices]\n",
    "        return np.random.choice(choices, p=probs)\n",
    "\n",
    "    else: \n",
    "        return sugestao_de_palavras(token[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dumb jokes and gags that get a region 5 chinese dvd of vampyr - der traum des allen grey , the silver'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gerar_n2(s, n_tokens):\n",
    "    REGEX = r'[A-Za-z0-9]\\w*|[^\\w\\s]'\n",
    "    tokens = re.findall(REGEX, s.lower())\n",
    "    size = len(tokens)\n",
    "    \n",
    "#     for n in range(n_tokens):\n",
    "#         if (tokens[-2], tokens[-1]) not in model_n2:\n",
    "#             print(tokens[-2], tokens[-1])\n",
    "#             tokens.append(sugestao_de_palavras(model_n2, (tokens[-2], tokens[-1])))\n",
    "#         else:\n",
    "#             tokens.append(sugestao_de_palavras(model, tokens[-1]))\n",
    "    \n",
    "    for n in range(n_tokens):\n",
    "        tokens.append(sugestao_de_palavras_n2((tokens[-2], tokens[-1])))\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "gerar_n2('dumb jokes', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 8\n",
    "**Objetivo: testar o gerador de textos em uma situação real**\n",
    "\n",
    "Escreva um trecho de um pequeno review de filmes em inglês. Use seu gerador para completar seu review. Como você avalia o desempenho dele?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "28a48ae6583e1b94abe98b0fc0a2fe606019d17909ce475d8d225fed8710924f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
