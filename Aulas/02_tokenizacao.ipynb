{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenização com RegEx\n",
    "\n",
    "Um problema que existe em processamento de linguagem natural é transformar uma string, que é algo que pode ser lido diretamente de textos, em uma lista de palavras individuais. Por exemplo, poderíamos querer transformar:\n",
    "\n",
    "`\"Minha string de entrada\"`\n",
    "\n",
    "em:\n",
    "\n",
    "`[\"Minha\", \"string\", \"de\", \"entrada\"]`\n",
    "\n",
    "Para isso, temos que toma algumas decisões, como:\n",
    "\n",
    "* As palavras são case-sensitive, isto é, diferenciamos caixa-alta de caixa-baixa?\n",
    "* O que fazemos com as pontuações?\n",
    "\n",
    "Nesta aula, vamos partir das expressões regulares e usar a biblioteca `re` para fazer tokenização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As onças pintadas são animais notáveis por seus hábitos de caça. Elas são caçadoras solitárias e usam sua habilidade de rastreamento para encontrar suas presas, geralmente animais como veados e javalis. O IBAMA, instituto responsável por proteger a fauna brasileira, monitora a população de onças e implementa medidas para protegê-las contra a caça ilegal. Além disso, o Ibama também trabalha para preservar o habitat dessas belas criaturas, garantindo que possam continuar a caçar de forma natural e sustentável. Ao preservarmos as onças pintadas e seus hábitos de caça, estamos protegendo a biodiversidade do nosso planeta.\n"
     ]
    }
   ],
   "source": [
    "entrada = \"As onças pintadas são animais notáveis por seus hábitos de caça. Elas são caçadoras solitárias e usam sua habilidade de rastreamento para encontrar suas presas, geralmente animais como veados e javalis. O IBAMA, instituto responsável por proteger a fauna brasileira, monitora a população de onças e implementa medidas para protegê-las contra a caça ilegal. Além disso, o Ibama também trabalha para preservar o habitat dessas belas criaturas, garantindo que possam continuar a caçar de forma natural e sustentável. Ao preservarmos as onças pintadas e seus hábitos de caça, estamos protegendo a biodiversidade do nosso planeta.\"\n",
    "print(entrada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "**Objetivo: usar a biblioteca string para separar palavras**\n",
    "\n",
    "Uma maneira de separar palavras em uma string é  usar a biblioteca `string`. Isso pode ser feito manualmente combinando:\n",
    "\n",
    "* `s = s.replace(x, y)`: troca todas as ocorrências da string `x` por `y` dentro da string `s`\n",
    "* `s = s.split()`: divide a string `s` em uma lista de strings usando os caracteres espaço e fim de linha.\n",
    "* `s = s.upper()`: converte a string `s` para caixa alta.\n",
    "\n",
    "Usando somente a biblioteca `string`, escreva um tokenizador para o texto da nossa entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AS', 'ONÇAS', 'PINTADAS', 'SÃO', 'ANIMAIS', 'NOTÁVEIS', 'POR', 'SEUS', 'HÁBITOS', 'DE', 'CAÇA', 'ELAS', 'SÃO', 'CAÇADORAS', 'SOLITÁRIAS', 'E', 'USAM', 'SUA', 'HABILIDADE', 'DE', 'RASTREAMENTO', 'PARA', 'ENCONTRAR', 'SUAS', 'PRESAS', 'GERALMENTE', 'ANIMAIS', 'COMO', 'VEADOS', 'E', 'JAVALIS', 'O', 'IBAMA', 'INSTITUTO', 'RESPONSÁVEL', 'POR', 'PROTEGER', 'A', 'FAUNA', 'BRASILEIRA', 'MONITORA', 'A', 'POPULAÇÃO', 'DE', 'ONÇAS', 'E', 'IMPLEMENTA', 'MEDIDAS', 'PARA', 'PROTEGÊ-LAS', 'CONTRA', 'A', 'CAÇA', 'ILEGAL', 'ALÉM', 'DISSO', 'O', 'IBAMA', 'TAMBÉM', 'TRABALHA', 'PARA', 'PRESERVAR', 'O', 'HABITAT', 'DESSAS', 'BELAS', 'CRIATURAS', 'GARANTINDO', 'QUE', 'POSSAM', 'CONTINUAR', 'A', 'CAÇAR', 'DE', 'FORMA', 'NATURAL', 'E', 'SUSTENTÁVEL', 'AO', 'PRESERVARMOS', 'AS', 'ONÇAS', 'PINTADAS', 'E', 'SEUS', 'HÁBITOS', 'DE', 'CAÇA', 'ESTAMOS', 'PROTEGENDO', 'A', 'BIODIVERSIDADE', 'DO', 'NOSSO', 'PLANETA']\n"
     ]
    }
   ],
   "source": [
    "s = entrada.replace('.', '').replace(',', '').upper().split()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "**Objetivo: usar expressões regulares para fazer um tokenizador**\n",
    "\n",
    "A biblioteca `re` tem uma função chamada `findall` que retorna todas as ocorrências de uma determinada expressão regular dentro de uma string. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ola', 'Olaaaaaa', 'Olaaaaaaaaaaa']\n"
     ]
    }
   ],
   "source": [
    "s = re.findall(\"[Oo]la+\", 'Ola, mundo! Olaaaaaa! Olaaaaaaaaaaa??? Alguém aí?')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando `re.findall`, escreva um tokenizador semelhante ao que você escreveu anteriormente usando a biblioteca `string`. Os resultados devem ser iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AS', 'ONÇAS', 'PINTADAS', 'SÃO', 'ANIMAIS', 'NOTÁVEIS', 'POR', 'SEUS', 'HÁBITOS', 'DE', 'CAÇA', 'ELAS', 'SÃO', 'CAÇADORAS', 'SOLITÁRIAS', 'E', 'USAM', 'SUA', 'HABILIDADE', 'DE', 'RASTREAMENTO', 'PARA', 'ENCONTRAR', 'SUAS', 'PRESAS', 'GERALMENTE', 'ANIMAIS', 'COMO', 'VEADOS', 'E', 'JAVALIS', 'O', 'IBAMA', 'INSTITUTO', 'RESPONSÁVEL', 'POR', 'PROTEGER', 'A', 'FAUNA', 'BRASILEIRA', 'MONITORA', 'A', 'POPULAÇÃO', 'DE', 'ONÇAS', 'E', 'IMPLEMENTA', 'MEDIDAS', 'PARA', 'PROTEGÊ', 'LAS', 'CONTRA', 'A', 'CAÇA', 'ILEGAL', 'ALÉM', 'DISSO', 'O', 'IBAMA', 'TAMBÉM', 'TRABALHA', 'PARA', 'PRESERVAR', 'O', 'HABITAT', 'DESSAS', 'BELAS', 'CRIATURAS', 'GARANTINDO', 'QUE', 'POSSAM', 'CONTINUAR', 'A', 'CAÇAR', 'DE', 'FORMA', 'NATURAL', 'E', 'SUSTENTÁVEL', 'AO', 'PRESERVARMOS', 'AS', 'ONÇAS', 'PINTADAS', 'E', 'SEUS', 'HÁBITOS', 'DE', 'CAÇA', 'ESTAMOS', 'PROTEGENDO', 'A', 'BIODIVERSIDADE', 'DO', 'NOSSO', 'PLANETA']\n"
     ]
    }
   ],
   "source": [
    "# Faça o exercício aqui\n",
    "output = re.findall(r\"[A-Za-z0-9]\\w*\", entrada.upper())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3\n",
    "**Objetivo: fazer um tokenizador assumindo que pontuações são tokens**\n",
    "\n",
    "Um problema da tokenização, na forma que foi feita, é que as pontuações são excluídas. Uma outra estratégia é considerar que pontuações são tokens, isto é:\n",
    "\n",
    "`\"uma frase, uma vírgula\"`\n",
    "\n",
    "seria tokenizado como:\n",
    "\n",
    "`[\"uma\", \"frase\", \",\", \"uma\", \"vírgula\"]`\n",
    "\n",
    "Escreva uma nova expressão para usar `findall` e tokenizar nossa frase de entrada. Se precisar, continue usando a função `upper()` da biblioteca `string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AS', 'ONÇAS', 'PINTADAS', 'SÃO', 'ANIMAIS', 'NOTÁVEIS', 'POR', 'SEUS', 'HÁBITOS', 'DE', 'CAÇA', '.', 'ELAS', 'SÃO', 'CAÇADORAS', 'SOLITÁRIAS', 'E', 'USAM', 'SUA', 'HABILIDADE', 'DE', 'RASTREAMENTO', 'PARA', 'ENCONTRAR', 'SUAS', 'PRESAS', ',', 'GERALMENTE', 'ANIMAIS', 'COMO', 'VEADOS', 'E', 'JAVALIS', '.', 'O', 'IBAMA', ',', 'INSTITUTO', 'RESPONSÁVEL', 'POR', 'PROTEGER', 'A', 'FAUNA', 'BRASILEIRA', ',', 'MONITORA', 'A', 'POPULAÇÃO', 'DE', 'ONÇAS', 'E', 'IMPLEMENTA', 'MEDIDAS', 'PARA', 'PROTEGÊ', '-', 'LAS', 'CONTRA', 'A', 'CAÇA', 'ILEGAL', '.', 'ALÉM', 'DISSO', ',', 'O', 'IBAMA', 'TAMBÉM', 'TRABALHA', 'PARA', 'PRESERVAR', 'O', 'HABITAT', 'DESSAS', 'BELAS', 'CRIATURAS', ',', 'GARANTINDO', 'QUE', 'POSSAM', 'CONTINUAR', 'A', 'CAÇAR', 'DE', 'FORMA', 'NATURAL', 'E', 'SUSTENTÁVEL', '.', 'AO', 'PRESERVARMOS', 'AS', 'ONÇAS', 'PINTADAS', 'E', 'SEUS', 'HÁBITOS', 'DE', 'CAÇA', ',', 'ESTAMOS', 'PROTEGENDO', 'A', 'BIODIVERSIDADE', 'DO', 'NOSSO', 'PLANETA', '.']\n"
     ]
    }
   ],
   "source": [
    "# Resolva o exercício aqui\n",
    "output = re.findall(r\"[A-Za-z0-9]\\w*|[^\\w\\s]\", entrada.upper())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 4\n",
    "**Objetivo: encontrar estatísticas de textos**\n",
    "\n",
    "O trecho de código abaixo faz o download do livro \"Quincas Borba\", de Machado de Assis, do [Portal Domínio Público](http://machado.mec.gov.br/obra-completa-lista), e então lê o PDF para uma string. Ele deve levar por volta de 1 minuto para executar, então execute a célula e siga para o restante do enunciado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer.six in c:\\users\\roger\\anaconda3\\lib\\site-packages (20221105)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\roger\\anaconda3\\lib\\site-packages (from pdfminer.six) (37.0.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\roger\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\roger\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\roger\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pdfminer.six\n",
    "from pdfminer.high_level import extract_text\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"http://machado.mec.gov.br/obra-completa-lista/item/download/14_7bbc6c42393beeac1fd963c16d935f40\", \"quincas.pdf\")\n",
    "texto = extract_text(\"quincas.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir das estratégias de tokenização que executamos, encontre:\n",
    "\n",
    "1. Quantas palavras há no texto?\n",
    "1. Quantas palavras *únicas* há no texto (isto é, cada palavra só é contada uma vez)?\n",
    "1. Quantas vezes cada palavra única aparece no texto?\n",
    "\n",
    "Dica: lembre-se das estruturas `set()` e `dict()` em Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QUINCAS',\n",
       " 'BORBA',\n",
       " 'TEXTO',\n",
       " 'FONTE',\n",
       " 'OBRA',\n",
       " 'COMPLETA',\n",
       " 'MACHADO',\n",
       " 'DE',\n",
       " 'ASSIS',\n",
       " 'RIO',\n",
       " 'DE',\n",
       " 'JANEIRO',\n",
       " 'EDITORA',\n",
       " 'NOVA',\n",
       " 'AGUILAR',\n",
       " '1994',\n",
       " 'PUBLICADO',\n",
       " 'ORIGINALMENTE',\n",
       " 'EM',\n",
       " 'FOLHETINS',\n",
       " 'DE',\n",
       " '1886',\n",
       " 'A',\n",
       " '1891',\n",
       " 'EM',\n",
       " 'A',\n",
       " 'ESTAÇÃO',\n",
       " 'PUBLICADO',\n",
       " 'EM',\n",
       " 'VOLUME',\n",
       " 'PELA',\n",
       " 'GARNIER',\n",
       " 'RIO',\n",
       " 'DE',\n",
       " 'JANEIRO',\n",
       " 'NO',\n",
       " 'MESMO',\n",
       " 'ANO',\n",
       " 'DE',\n",
       " '1891',\n",
       " 'COM',\n",
       " 'SUBSTANCIAIS',\n",
       " 'DIFERENÇAS',\n",
       " 'COM',\n",
       " 'RELAÇÃO',\n",
       " 'AOS',\n",
       " 'FOLHETINS',\n",
       " 'O',\n",
       " 'QUE',\n",
       " 'AQUI',\n",
       " 'VAI',\n",
       " 'JUSTAMENTE',\n",
       " 'A',\n",
       " 'EDIÇÃO',\n",
       " 'EM',\n",
       " 'LIVRO',\n",
       " 'PRÓLOGO',\n",
       " 'DA',\n",
       " '3ª',\n",
       " 'EDIÇÃO',\n",
       " 'A',\n",
       " 'SEGUNDA',\n",
       " 'EDIÇÃO',\n",
       " 'DESTE',\n",
       " 'LIVRO',\n",
       " 'ACABOU',\n",
       " 'MAIS',\n",
       " 'DEPRESSA',\n",
       " 'QUE',\n",
       " 'A',\n",
       " 'PRIMEIRA',\n",
       " 'AQUI',\n",
       " 'SAI',\n",
       " 'ELE',\n",
       " 'EM',\n",
       " 'TERCEIRA',\n",
       " 'SEM',\n",
       " 'OUTRA',\n",
       " 'ALTERAÇÃO',\n",
       " 'ALÉM',\n",
       " 'DA',\n",
       " 'EMENDA',\n",
       " 'DE',\n",
       " 'ALGUNS',\n",
       " 'ERROS',\n",
       " 'TIPOGRÁFICOS',\n",
       " 'TAIS',\n",
       " 'E',\n",
       " 'TÃO',\n",
       " 'POUCOS',\n",
       " 'QUE',\n",
       " 'AINDA',\n",
       " 'CONSERVADOS',\n",
       " 'NÃO',\n",
       " 'ENCOBRIRIAM',\n",
       " 'O',\n",
       " 'SENTIDO',\n",
       " 'UM',\n",
       " 'AMIGO',\n",
       " 'E',\n",
       " 'CONFRADE',\n",
       " 'ILUSTRE',\n",
       " 'TEM',\n",
       " 'TEIMADO',\n",
       " 'COMIGO',\n",
       " 'PARA',\n",
       " 'QUE',\n",
       " 'DÊ',\n",
       " 'A',\n",
       " 'ESTE',\n",
       " 'LIVRO',\n",
       " 'O',\n",
       " 'SEGUIMENTO',\n",
       " 'DE',\n",
       " 'OUTRO',\n",
       " 'COM',\n",
       " 'AS',\n",
       " 'MEMÓRIAS',\n",
       " 'PÓSTUMAS',\n",
       " 'DE',\n",
       " 'BRÁS',\n",
       " 'CUBAS',\n",
       " 'DONDE',\n",
       " 'ESTE',\n",
       " 'FARÁ',\n",
       " 'VOCÊ',\n",
       " 'UMA',\n",
       " 'TRILOGIA',\n",
       " 'E',\n",
       " 'A',\n",
       " 'SOFIA',\n",
       " 'DE',\n",
       " 'QUINCAS',\n",
       " 'BORBA',\n",
       " 'OCUPARÁ',\n",
       " 'PROVEIO',\n",
       " 'EXCLUSIVAMENTE',\n",
       " 'A',\n",
       " 'TERCEIRA',\n",
       " 'PARTE',\n",
       " 'ALGUM',\n",
       " 'TEMPO',\n",
       " 'CUIDEI',\n",
       " 'QUE',\n",
       " 'PODIA',\n",
       " 'SER',\n",
       " 'MAS',\n",
       " 'RELENDO',\n",
       " 'AGORA',\n",
       " 'ESTAS',\n",
       " 'PÁGINAS',\n",
       " 'CONCLUO',\n",
       " 'QUE',\n",
       " 'NÃO',\n",
       " 'A',\n",
       " 'SOFIA',\n",
       " 'ESTÁ',\n",
       " 'AQUI',\n",
       " 'TODA',\n",
       " 'CONTINUÁ',\n",
       " 'LA',\n",
       " 'SERIA',\n",
       " 'REPETI',\n",
       " 'LA',\n",
       " 'E',\n",
       " 'ACASO',\n",
       " 'REPETIR',\n",
       " 'O',\n",
       " 'MESMO',\n",
       " 'SERIA',\n",
       " 'PECADO',\n",
       " 'CREIO',\n",
       " 'QUE',\n",
       " 'FOI',\n",
       " 'ASSIM',\n",
       " 'QUE',\n",
       " 'ME',\n",
       " 'TACHARAM',\n",
       " 'ESTE',\n",
       " 'E',\n",
       " 'ALGUNS',\n",
       " 'OUTROS',\n",
       " 'DOS',\n",
       " 'LIVROS',\n",
       " 'QUE',\n",
       " 'VIM',\n",
       " 'COMPONDO',\n",
       " 'PELO',\n",
       " 'TEMPO',\n",
       " 'FORA',\n",
       " 'NO',\n",
       " 'SILÊNCIO',\n",
       " 'DA',\n",
       " 'MINHA',\n",
       " 'VIDA',\n",
       " 'VOZES',\n",
       " 'HOUVE',\n",
       " 'GENEROSAS',\n",
       " 'E',\n",
       " 'FORTES',\n",
       " 'QUE',\n",
       " 'ENTÃO',\n",
       " 'ME',\n",
       " 'DEFENDERAM',\n",
       " 'JÁ',\n",
       " 'LHES',\n",
       " 'AGRADECI',\n",
       " 'EM',\n",
       " 'PARTICULAR',\n",
       " 'AGORA',\n",
       " 'O',\n",
       " 'FAÇO',\n",
       " 'CORDIAL',\n",
       " 'E',\n",
       " 'PUBLICAMENTE',\n",
       " '1889',\n",
       " 'M',\n",
       " 'DE',\n",
       " 'A',\n",
       " 'CAPÍTULO',\n",
       " 'PRIMEIRO',\n",
       " 'RUBIÃO',\n",
       " 'FITAVA',\n",
       " 'A',\n",
       " 'ENSEADA',\n",
       " 'ERAM',\n",
       " 'OITO',\n",
       " 'HORAS',\n",
       " 'DA',\n",
       " 'MANHÃ',\n",
       " 'QUEM',\n",
       " 'O',\n",
       " 'VISSE',\n",
       " 'COM',\n",
       " 'OS',\n",
       " 'POLEGARES',\n",
       " 'METIDOS',\n",
       " 'NO',\n",
       " 'CORDÃO',\n",
       " 'DO',\n",
       " 'CHAMBRE',\n",
       " 'JANELA',\n",
       " 'DE',\n",
       " 'UMA',\n",
       " 'GRANDE',\n",
       " 'CASA',\n",
       " 'DE',\n",
       " 'BOTAFOGO',\n",
       " 'CUIDARIA',\n",
       " 'QUE',\n",
       " 'ELE',\n",
       " 'ADMIRAVA',\n",
       " 'AQUELE',\n",
       " 'PEDAÇO',\n",
       " 'DE',\n",
       " 'GUA',\n",
       " 'QUIETA',\n",
       " 'MAS',\n",
       " 'EM',\n",
       " 'VERDADE',\n",
       " 'VOS',\n",
       " 'DIGO',\n",
       " 'QUE',\n",
       " 'PENSAVA',\n",
       " 'EM',\n",
       " 'OUTRA',\n",
       " 'COISA',\n",
       " 'COTEJAVA',\n",
       " 'O',\n",
       " 'PASSADO',\n",
       " 'COM',\n",
       " 'O',\n",
       " 'PRESENTE',\n",
       " 'QUE',\n",
       " 'ERA',\n",
       " 'HÁ',\n",
       " 'UM',\n",
       " 'ANO',\n",
       " 'PROFESSOR',\n",
       " 'QUE',\n",
       " 'AGORA',\n",
       " 'CAPITALISTA',\n",
       " 'OLHA',\n",
       " 'PARA',\n",
       " 'SI',\n",
       " 'PARA',\n",
       " 'AS',\n",
       " 'CHINELAS',\n",
       " 'UMAS',\n",
       " 'CHINELAS',\n",
       " 'DE',\n",
       " 'TÚNIS',\n",
       " 'QUE',\n",
       " 'LHE',\n",
       " 'DEU',\n",
       " 'RECENTE',\n",
       " 'AMIGO',\n",
       " 'CRISTIANO',\n",
       " 'PALHA',\n",
       " 'PARA',\n",
       " 'A',\n",
       " 'CASA',\n",
       " 'PARA',\n",
       " 'O',\n",
       " 'JARDIM',\n",
       " 'PARA',\n",
       " 'A',\n",
       " 'ENSEADA',\n",
       " 'PARA',\n",
       " 'OS',\n",
       " 'MORROS',\n",
       " 'E',\n",
       " 'PARA',\n",
       " 'O',\n",
       " 'CÉU',\n",
       " 'E',\n",
       " 'TUDO',\n",
       " 'DESDE',\n",
       " 'AS',\n",
       " 'CHINELAS',\n",
       " 'ATÉ',\n",
       " 'O',\n",
       " 'CÉU',\n",
       " 'TUDO',\n",
       " 'ENTRA',\n",
       " 'NA',\n",
       " 'MESMA',\n",
       " 'SENSAÇÃO',\n",
       " 'DE',\n",
       " 'PROPRIEDADE',\n",
       " 'VEJAM',\n",
       " 'COMO',\n",
       " 'DEUS',\n",
       " 'ESCREVE',\n",
       " 'DIREITO',\n",
       " 'POR',\n",
       " 'LINHAS',\n",
       " 'TORTAS',\n",
       " 'PENSA',\n",
       " 'ELE',\n",
       " 'SE',\n",
       " 'MANA',\n",
       " 'PIEDADE',\n",
       " 'TEM',\n",
       " 'CASADO',\n",
       " 'COM',\n",
       " 'QUINCAS',\n",
       " 'BORBA',\n",
       " 'APENAS',\n",
       " 'ME',\n",
       " 'DARIA',\n",
       " 'UMA',\n",
       " 'ESPERANÇA',\n",
       " 'COLATERAL',\n",
       " 'NÃO',\n",
       " 'CASOU',\n",
       " 'AMBOS',\n",
       " 'MORRERAM',\n",
       " 'E',\n",
       " 'AQUI',\n",
       " 'ESTÁ',\n",
       " 'TUDO',\n",
       " 'COMIGO',\n",
       " 'DE',\n",
       " 'MODO',\n",
       " 'QUE',\n",
       " 'O',\n",
       " 'QUE',\n",
       " 'PARECIA',\n",
       " 'UMA',\n",
       " 'DESGRAÇA',\n",
       " 'CAPÍTULO',\n",
       " 'II',\n",
       " 'QUE',\n",
       " 'ABISMO',\n",
       " 'QUE',\n",
       " 'HÁ',\n",
       " 'ENTRE',\n",
       " 'O',\n",
       " 'ESPÍRITO',\n",
       " 'E',\n",
       " 'O',\n",
       " 'CORAÇÃO',\n",
       " 'O',\n",
       " 'ESPÍRITO',\n",
       " 'DO',\n",
       " 'EX',\n",
       " 'PROFESSOR',\n",
       " 'VEXADO',\n",
       " 'DAQUELE',\n",
       " 'PENSAMENTO',\n",
       " 'ARREPIOU',\n",
       " 'CAMINHO',\n",
       " 'BUSCOU',\n",
       " 'OUTRO',\n",
       " 'ASSUNTO',\n",
       " 'UMA',\n",
       " 'CANOA',\n",
       " 'QUE',\n",
       " 'IA',\n",
       " 'PASSANDO',\n",
       " 'O',\n",
       " 'CORAÇÃO',\n",
       " 'PORÉM',\n",
       " 'DEIXOU',\n",
       " 'SE',\n",
       " 'ESTAR',\n",
       " 'A',\n",
       " 'BATER',\n",
       " 'DE',\n",
       " 'ALEGRIA',\n",
       " 'QUE',\n",
       " 'LHE',\n",
       " 'IMPORTA',\n",
       " 'A',\n",
       " 'CANOA',\n",
       " 'NEM',\n",
       " 'O',\n",
       " 'CANOEIRO',\n",
       " 'QUE',\n",
       " 'OS',\n",
       " 'OLHOS',\n",
       " 'DE',\n",
       " 'RUBIÃO',\n",
       " 'ACOMPANHAM',\n",
       " 'ARREGALADOS',\n",
       " 'ELE',\n",
       " 'CORAÇÃO',\n",
       " 'VAI',\n",
       " 'DIZENDO',\n",
       " 'QUE',\n",
       " 'UMA',\n",
       " 'VEZ',\n",
       " 'QUE',\n",
       " 'A',\n",
       " 'MANA',\n",
       " 'PIEDADE',\n",
       " 'TINHA',\n",
       " 'DE',\n",
       " 'MORRER',\n",
       " 'FOI',\n",
       " 'BOM',\n",
       " 'QUE',\n",
       " 'NÃO',\n",
       " 'CASASSE',\n",
       " 'PODIA',\n",
       " 'VIR',\n",
       " 'UM',\n",
       " 'FILHO',\n",
       " 'OU',\n",
       " 'UMA',\n",
       " 'FILHA',\n",
       " 'BONITA',\n",
       " 'CANOA',\n",
       " 'ANTES',\n",
       " 'ASSIM',\n",
       " 'COMO',\n",
       " 'OBEDECE',\n",
       " 'BEM',\n",
       " 'AOS',\n",
       " 'REMOS',\n",
       " 'DO',\n",
       " 'HOMEM',\n",
       " 'O',\n",
       " 'CERTO',\n",
       " 'QUE',\n",
       " 'ELES',\n",
       " 'ESTÃO',\n",
       " 'NO',\n",
       " 'CÉU',\n",
       " 'CAPÍTULO',\n",
       " 'III',\n",
       " 'UM',\n",
       " 'CRIADO',\n",
       " 'TROUXE',\n",
       " 'O',\n",
       " 'CAFÉ',\n",
       " 'RUBIÃO',\n",
       " 'PEGOU',\n",
       " 'NA',\n",
       " 'XÍCARA',\n",
       " 'E',\n",
       " 'ENQUANTO',\n",
       " 'LHE',\n",
       " 'DEITAVA',\n",
       " 'AÇÚCAR',\n",
       " 'IA',\n",
       " 'DISFARÇADAMENTE',\n",
       " 'MIRANDO',\n",
       " 'A',\n",
       " 'BANDEJA',\n",
       " 'QUE',\n",
       " 'ERA',\n",
       " 'DE',\n",
       " 'PRATA',\n",
       " 'LAVRADA',\n",
       " 'PRATA',\n",
       " 'OURO',\n",
       " 'ERAM',\n",
       " 'OS',\n",
       " 'METAIS',\n",
       " 'QUE',\n",
       " 'AMAVA',\n",
       " 'DE',\n",
       " 'CORAÇÃO',\n",
       " 'NÃO',\n",
       " 'GOSTAVA',\n",
       " 'DE',\n",
       " 'BRONZE',\n",
       " 'MAS',\n",
       " 'O',\n",
       " 'AMIGO',\n",
       " 'PALHA',\n",
       " 'DISSE',\n",
       " 'LHE',\n",
       " 'QUE',\n",
       " 'ERA',\n",
       " 'MATÉRIA',\n",
       " 'DE',\n",
       " 'PREÇO',\n",
       " 'E',\n",
       " 'ASSIM',\n",
       " 'SE',\n",
       " 'EXPLICA',\n",
       " 'ESTE',\n",
       " 'PAR',\n",
       " 'DE',\n",
       " 'FIGURAS',\n",
       " 'QUE',\n",
       " 'AQUI',\n",
       " 'ESTÁ',\n",
       " 'NA',\n",
       " 'SALA',\n",
       " 'UM',\n",
       " 'MEFISTÓFELES',\n",
       " 'E',\n",
       " 'UM',\n",
       " 'FAUSTO',\n",
       " 'TIVESSE',\n",
       " 'PORÉM',\n",
       " 'DE',\n",
       " 'ESCOLHER',\n",
       " 'ESCOLHERIA',\n",
       " 'A',\n",
       " 'BANDEJA',\n",
       " 'PRIMOR',\n",
       " 'DE',\n",
       " 'ARGENTARIA',\n",
       " 'EXECUÇÃO',\n",
       " 'FINA',\n",
       " 'E',\n",
       " 'ACABADA',\n",
       " 'O',\n",
       " 'CRIADO',\n",
       " 'ESPERAVA',\n",
       " 'TESO',\n",
       " 'E',\n",
       " 'SÉRIO',\n",
       " 'ERA',\n",
       " 'ESPANHOL',\n",
       " 'E',\n",
       " 'NÃO',\n",
       " 'FOI',\n",
       " 'SEM',\n",
       " 'RESISTÊNCIA',\n",
       " 'QUE',\n",
       " 'RUBIÃO',\n",
       " 'O',\n",
       " 'ACEITOU',\n",
       " 'DAS',\n",
       " 'MÃOS',\n",
       " 'DE',\n",
       " 'CRISTIANO',\n",
       " 'POR',\n",
       " 'MAIS',\n",
       " 'QUE',\n",
       " 'LHE',\n",
       " 'DISSESSE',\n",
       " 'QUE',\n",
       " 'ESTAVA',\n",
       " 'ACOSTUMADO',\n",
       " 'AOS',\n",
       " 'SEUS',\n",
       " 'CRIOULOS',\n",
       " 'DE',\n",
       " 'MINAS',\n",
       " 'E',\n",
       " 'NÃO',\n",
       " 'QUERIA',\n",
       " 'LÍNGUAS',\n",
       " 'ESTRANGEIRAS',\n",
       " 'EM',\n",
       " 'CASA',\n",
       " 'O',\n",
       " 'AMIGO',\n",
       " 'PALHA',\n",
       " 'INSISTIU',\n",
       " 'DEMONSTRANDO',\n",
       " 'LHE',\n",
       " 'A',\n",
       " 'NECESSIDADE',\n",
       " 'DE',\n",
       " 'TER',\n",
       " 'CRIADOS',\n",
       " 'BRANCOS',\n",
       " 'RUBIÃO',\n",
       " 'CEDEU',\n",
       " 'COM',\n",
       " 'PENA',\n",
       " 'O',\n",
       " 'SEU',\n",
       " 'BOM',\n",
       " 'PAJEM',\n",
       " 'QUE',\n",
       " 'ELE',\n",
       " 'QUERIA',\n",
       " 'PÔR',\n",
       " 'NA',\n",
       " 'SALA',\n",
       " 'COMO',\n",
       " 'UM',\n",
       " 'PEDAÇO',\n",
       " 'DA',\n",
       " 'PROVÍNCIA',\n",
       " 'NEM',\n",
       " 'O',\n",
       " 'PÔDE',\n",
       " 'DEIXAR',\n",
       " 'NA',\n",
       " 'COZINHA',\n",
       " 'ONDE',\n",
       " 'REINAVA',\n",
       " 'UM',\n",
       " 'FRANCÊS',\n",
       " 'JEAN',\n",
       " 'FOI',\n",
       " 'DEGRADADO',\n",
       " 'A',\n",
       " 'OUTROS',\n",
       " 'SERVIÇOS',\n",
       " 'QUINCAS',\n",
       " 'BORBA',\n",
       " 'ESTÁ',\n",
       " 'MUITO',\n",
       " 'IMPACIENTE',\n",
       " 'PERGUNTOU',\n",
       " 'RUBIÃO',\n",
       " 'BEBENDO',\n",
       " 'O',\n",
       " 'LTIMO',\n",
       " 'GOLE',\n",
       " 'DE',\n",
       " 'CAFÉ',\n",
       " 'E',\n",
       " 'LANÇANDO',\n",
       " 'UM',\n",
       " 'LTIMO',\n",
       " 'OLHAR',\n",
       " 'BANDEJA',\n",
       " 'ME',\n",
       " 'PARECE',\n",
       " 'QUE',\n",
       " 'SÍ',\n",
       " 'LÁ',\n",
       " 'VOU',\n",
       " 'SOLTÁ',\n",
       " 'LO',\n",
       " 'NÃO',\n",
       " 'FOI',\n",
       " 'DEIXOU',\n",
       " 'SE',\n",
       " 'FICAR',\n",
       " 'ALGUM',\n",
       " 'TEMPO',\n",
       " 'A',\n",
       " 'OLHAR',\n",
       " 'PARA',\n",
       " 'OS',\n",
       " 'MÓVEIS',\n",
       " 'VENDO',\n",
       " 'AS',\n",
       " 'PEQUENAS',\n",
       " 'GRAVURAS',\n",
       " 'INGLESAS',\n",
       " 'QUE',\n",
       " 'PENDIAM',\n",
       " 'DA',\n",
       " 'PAREDE',\n",
       " 'POR',\n",
       " 'CIMA',\n",
       " 'DOS',\n",
       " 'DOIS',\n",
       " 'BRONZES',\n",
       " 'RUBIÃO',\n",
       " 'PENSOU',\n",
       " 'NA',\n",
       " 'BELA',\n",
       " 'SOFIA',\n",
       " 'MULHER',\n",
       " 'DO',\n",
       " 'PALHA',\n",
       " 'DEU',\n",
       " 'ALGUNS',\n",
       " 'PASSOS',\n",
       " 'E',\n",
       " 'FOI',\n",
       " 'SENTAR',\n",
       " 'SE',\n",
       " 'NO',\n",
       " 'POUF',\n",
       " 'AO',\n",
       " 'CENTRO',\n",
       " 'DA',\n",
       " 'SALA',\n",
       " 'OLHANDO',\n",
       " 'PARA',\n",
       " 'LONGE',\n",
       " 'FOI',\n",
       " 'ELA',\n",
       " 'QUE',\n",
       " 'ME',\n",
       " 'RECOMENDOU',\n",
       " 'AQUELES',\n",
       " 'DOIS',\n",
       " 'QUADRINHOS',\n",
       " 'QUANDO',\n",
       " 'ANDÁVAMOS',\n",
       " 'OS',\n",
       " 'TRÊS',\n",
       " 'A',\n",
       " 'VER',\n",
       " 'COISAS',\n",
       " 'PARA',\n",
       " 'COMPRAR',\n",
       " 'ESTAVA',\n",
       " 'TÃO',\n",
       " 'BONITA',\n",
       " 'MAS',\n",
       " 'O',\n",
       " 'QUE',\n",
       " 'EU',\n",
       " 'MAIS',\n",
       " 'GOSTO',\n",
       " 'DELA',\n",
       " 'SÃO',\n",
       " 'OS',\n",
       " 'OMBROS',\n",
       " 'QUE',\n",
       " 'VI',\n",
       " 'NO',\n",
       " 'BAILE',\n",
       " 'DO',\n",
       " 'CORONEL',\n",
       " 'QUE',\n",
       " 'OMBROS',\n",
       " 'PARECEM',\n",
       " 'DE',\n",
       " 'CERA',\n",
       " 'TÃO',\n",
       " 'LISOS',\n",
       " 'TÃO',\n",
       " 'BRANCOS',\n",
       " 'OS',\n",
       " 'BRAÇOS',\n",
       " 'TAMBÉM',\n",
       " 'OH',\n",
       " 'OS',\n",
       " 'BRAÇOS',\n",
       " 'QUE',\n",
       " 'BEM',\n",
       " 'FEITOS',\n",
       " 'RUBIÃO',\n",
       " 'SUSPIROU',\n",
       " 'CRUZOU',\n",
       " 'AS',\n",
       " 'PERNAS',\n",
       " 'E',\n",
       " 'BATEU',\n",
       " 'COM',\n",
       " 'AS',\n",
       " 'BORLAS',\n",
       " 'DO',\n",
       " 'CHAMBRE',\n",
       " 'SOBRE',\n",
       " 'OS',\n",
       " 'JOELHOS',\n",
       " 'SENTIA',\n",
       " 'QUE',\n",
       " 'NÃO',\n",
       " 'ERA',\n",
       " 'INTEIRAMENTE',\n",
       " 'FELIZ',\n",
       " 'MAS',\n",
       " 'SENTIA',\n",
       " 'TAMBÉM',\n",
       " 'QUE',\n",
       " 'NÃO',\n",
       " 'ESTAVA',\n",
       " 'LONGE',\n",
       " 'A',\n",
       " 'FELICIDADE',\n",
       " 'COMPLETA',\n",
       " 'RECOMPUNHA',\n",
       " 'DE',\n",
       " 'CABEÇA',\n",
       " 'UNS',\n",
       " 'MODOS',\n",
       " 'UNS',\n",
       " 'OLHOS',\n",
       " 'UNS',\n",
       " 'REQUEBROS',\n",
       " 'SEM',\n",
       " 'EXPLICAÇÃO',\n",
       " 'A',\n",
       " 'NÃO',\n",
       " 'SER',\n",
       " 'ESTA',\n",
       " 'QUE',\n",
       " 'ELA',\n",
       " 'O',\n",
       " 'AMAVA',\n",
       " 'E',\n",
       " 'QUE',\n",
       " 'O',\n",
       " 'AMAVA',\n",
       " 'MUITO',\n",
       " 'NÃO',\n",
       " 'ERA',\n",
       " 'VELHO',\n",
       " 'IA',\n",
       " 'FAZER',\n",
       " 'QUARENTA',\n",
       " 'E',\n",
       " 'UM',\n",
       " 'ANOS',\n",
       " 'E',\n",
       " 'RIGOROSAMENTE',\n",
       " 'PARECIA',\n",
       " 'MENOS',\n",
       " 'ESTA',\n",
       " 'OBSERVAÇÃO',\n",
       " 'FOI',\n",
       " 'ACOMPANHADA',\n",
       " 'DE',\n",
       " 'UM',\n",
       " 'GESTO',\n",
       " 'PASSOU',\n",
       " 'A',\n",
       " 'MÃO',\n",
       " 'PELO',\n",
       " 'QUEIXO',\n",
       " 'BARBEADO',\n",
       " 'TODOS',\n",
       " 'OS',\n",
       " 'DIAS',\n",
       " 'COISA',\n",
       " 'QUE',\n",
       " 'NÃO',\n",
       " 'FAZIA',\n",
       " 'DANTES',\n",
       " 'POR',\n",
       " 'ECONOMIA',\n",
       " 'E',\n",
       " 'DESNECESSIDADE',\n",
       " 'UM',\n",
       " 'SIMPLES',\n",
       " 'PROFESSOR',\n",
       " 'USAVA',\n",
       " 'SUÍÇAS',\n",
       " 'MAIS',\n",
       " 'TARDE',\n",
       " 'DEIXOU',\n",
       " 'CRESCER',\n",
       " 'A',\n",
       " 'BARBA',\n",
       " 'TODA',\n",
       " 'TÃO',\n",
       " 'MACIAS',\n",
       " 'QUE',\n",
       " 'DAVA',\n",
       " 'GOSTO',\n",
       " 'PASSAR',\n",
       " 'OS',\n",
       " 'DEDOS',\n",
       " 'POR',\n",
       " 'ELAS',\n",
       " 'E',\n",
       " 'RECORDAVA',\n",
       " 'ASSIM',\n",
       " 'O',\n",
       " 'PRIMEIRO',\n",
       " 'ENCONTRO',\n",
       " 'NA',\n",
       " 'ESTAÇÃO',\n",
       " 'DE',\n",
       " 'VASSOURAS',\n",
       " 'ONDE',\n",
       " 'SOFIA',\n",
       " 'E',\n",
       " 'O',\n",
       " 'MARIDO',\n",
       " 'ENTRARAM',\n",
       " 'NO',\n",
       " 'TREM',\n",
       " 'DA',\n",
       " 'ESTRADA',\n",
       " 'DE',\n",
       " 'FERRO',\n",
       " 'NO',\n",
       " 'MESMO',\n",
       " 'CARRO',\n",
       " 'EM',\n",
       " 'QUE',\n",
       " 'ELE',\n",
       " 'DESCIA',\n",
       " 'DE',\n",
       " 'MINAS',\n",
       " 'FOI',\n",
       " 'ALI',\n",
       " 'QUE',\n",
       " 'ACHOU',\n",
       " 'AQUELE',\n",
       " 'PAR',\n",
       " 'DE',\n",
       " 'OLHOS',\n",
       " 'VIÇOSOS',\n",
       " 'QUE',\n",
       " 'PARECIAM',\n",
       " 'REPETIR',\n",
       " 'A',\n",
       " 'EXORTAÇÃO',\n",
       " 'DO',\n",
       " 'PROFETA',\n",
       " 'TODOS',\n",
       " 'VÓS',\n",
       " 'QUE',\n",
       " 'TENDES',\n",
       " 'SEDE',\n",
       " 'VINDE',\n",
       " 'S',\n",
       " 'GUAS',\n",
       " 'NÃO',\n",
       " 'TRAZIA',\n",
       " 'IDÉIAS',\n",
       " 'ADEQUADAS',\n",
       " 'AO',\n",
       " 'CONVITE',\n",
       " 'VERDADE',\n",
       " 'VINHA',\n",
       " 'COM',\n",
       " 'A',\n",
       " 'HERANÇA',\n",
       " 'NA',\n",
       " 'CABEÇA',\n",
       " 'O',\n",
       " 'TESTAMENTO',\n",
       " 'O',\n",
       " 'INVENTÁRIO',\n",
       " 'COISAS',\n",
       " 'QUE',\n",
       " 'PRECISO',\n",
       " 'EXPLICAR',\n",
       " 'PRIMEIRO',\n",
       " 'A',\n",
       " 'FIM',\n",
       " 'DE',\n",
       " 'ENTENDER',\n",
       " 'O',\n",
       " 'PRESENTE',\n",
       " 'E',\n",
       " 'O',\n",
       " 'FUTURO',\n",
       " 'DEIXEMOS',\n",
       " 'RUBIÃO',\n",
       " 'NA',\n",
       " 'SALA',\n",
       " 'DE',\n",
       " 'BOTAFOGO',\n",
       " 'BATENDO',\n",
       " 'COM',\n",
       " 'AS',\n",
       " 'BORLAS',\n",
       " 'DO',\n",
       " 'CHAMBRE',\n",
       " 'NOS',\n",
       " 'JOELHOS',\n",
       " 'E',\n",
       " 'CUIDANDO',\n",
       " 'NA',\n",
       " 'BELA',\n",
       " 'SOFIA',\n",
       " 'VEM',\n",
       " 'COMIGO',\n",
       " 'LEITOR',\n",
       " 'VAMOS',\n",
       " 'VÊ',\n",
       " 'LO',\n",
       " 'MESES',\n",
       " 'ANTES',\n",
       " 'CABECEIRA',\n",
       " ...]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = re.findall(r\"[A-Za-z0-9]\\w*\", texto.upper())\n",
    "#tokens = re.findall(r\"[A-Za-z0-9]\\w*|[^\\w\\s]\", texto.upper())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há 76876 palavras no texto\n",
      "Há 10041 palavras únicas no texto\n"
     ]
    }
   ],
   "source": [
    "# 1. Quantas palavras há no texto?\n",
    "print(f'Há {len(tokens)} palavras no texto')\n",
    "\n",
    "#2. Quantas palavras únicas há no texto\n",
    "set_tokens = set(tokens)\n",
    "print(f'Há {len(set_tokens)} palavras únicas no texto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10041/10041 [00:45<00:00, 222.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "#3. Quantas vezes cada palavra única aparece no texto?\n",
    "dict_tokens = dict()\n",
    "error_tokens = []\n",
    "for token in tqdm(set_tokens):\n",
    "    try:\n",
    "        t = re.findall(token, texto.upper())\n",
    "        dict_tokens[token] = len(t)\n",
    "    except:\n",
    "        error_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, texto):\n",
    "        self.texto = texto\n",
    "        self.tokens = re.findall(r\"[A-Za-z0-9]\\w*\", self.texto.upper())\n",
    "        self.unicas = set(self.tokens)\n",
    "        self.freq_palavras = dict()\n",
    "        self.frequencia()\n",
    "\n",
    "    def frequencia(self):\n",
    "        for token in tqdm(self.unicas):\n",
    "            t = re.findall(token, self.texto.upper())\n",
    "            self.freq_palavras[token] = len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5\n",
    "**Objetivo: usar estatísticas de texto para comparar duas obras**\n",
    "\n",
    "O trecho abaixo faz o download e conversão do livro \"O pequeno Príncipe\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://www.sesirs.org.br/sites/default/files/paragraph--files/o_pequeno_principe_-_antoine_de_saint-exupery.pdf\", \"principe.pdf\")\n",
    "texto2 = extract_text(\"principe.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base neste texto:\n",
    "\n",
    "1. Conte as palavras únicas de O Pequeno Príncipe usando o mesmo procedimento que você fez para \"Quincas Borba\".\n",
    "1. Encontre palavras que são muito frequentes em ambos os textos,\n",
    "1. Encontre palavras que são muito frequentes em um dos textos, mas que são pouco presentes no outro texto.\n",
    "1. A presença de algumas palavras pode ser usada para indicar o significado dos livros. Quais palavras seriam essas, em cada um dos livros?\n",
    "1. Algumas palavras são muito comuns, mas não tem um significado relacionado ao livro, como \"não\" ou \"muito\". Que palavras poderiam entrar nessa categoria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10041/10041 [00:48<00:00, 209.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenizer do quincas borba\n",
    "tokenizer_qb = Tokenizer(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2631/2631 [00:03<00:00, 769.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenizer do pequeno príncipe\n",
    "tokenizer_pp = Tokenizer(texto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2631"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Conte as palavras únicas de O Pequeno Príncipe usando o mesmo procedimento que você fez para \"Quincas Borba\".\n",
    "len(tokenizer_pp.unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encontre palavras que são muito frequentes em ambos os textos\n",
    "freq_pp = tokenizer_pp.freq_palavras\n",
    "num_unicas = len(tokenizer_pp.unicas)\n",
    "for key, value in freq_pp.items():\n",
    "    freq_pp[key] = value/num_unicas\n",
    "    \n",
    "freq_qb = tokenizer_qb.freq_palavras\n",
    "num_unicas = len(tokenizer_qb.unicas)\n",
    "for key, value in freq_qb.items():\n",
    "    freq_qb[key] = value/num_unicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E': 0.0011182923945282405, 'A': 0.0009293340620075148, 'O': 0.0008794941348518187, 'S': 0.0006824458431406031, 'I': 0.00052411378469816, 'D': 0.00036968224229398883, 'DE': 0.00014547480187184321, 'V': 0.00012322741409799627, 'SE': 0.00012062707007248171, 'AS': 0.00011773779893302107}\n",
      "{'A': 4.625037346877801, 'E': 4.019818743153072, 'O': 3.6854894930783786, 'S': 2.641370381436112, 'I': 2.1025794243601235, 'D': 1.6677621750821632, 'U': 1.6541181157255254, 'N': 1.6241410218105767, 'M': 1.5596056169704213, 'C': 1.129668359725127}\n"
     ]
    }
   ],
   "source": [
    "# Classifica o dicionário em ordem decrescente com base em seus valores\n",
    "sorted_pp = dict(sorted(freq_pp.items(), key=lambda x: x[1], reverse=True))\n",
    "sorted_qb = dict(sorted(freq_qb.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Retorna os 10 maiores valores do dicionário\n",
    "top_10_pp = {k: sorted_pp[k] for k in list(sorted_pp)[:10]}\n",
    "top_10_qb = {k: sorted_qb[k] for k in list(sorted_qb)[:10]}\n",
    "\n",
    "print(top_10_pp)\n",
    "print(top_10_qb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "42e34ec1a81382d7a35a13fd98192c35dabe0890684b7b0a474deec672e3df02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
